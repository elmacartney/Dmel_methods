---
title: "Zantiks manipulation scripts"
author: "Szymek Drobniak, Erin Macartney & Shinichi Nakagawa"
date: "`r Sys.Date()`"
output:
  rmdformats::robobook:
      
      code_folding: show
      toc_depth: 3
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message = F}
library(tidyverse)
library(lme4)
library(lmerTest)
library(here) # write out the path
library(kableExtra)
library(sjlabelled)
library(ggpubr)
library(rstatix)
library(car)
library(RColorBrewer)

col_accent1 = "slateblue1"
col_accent2 = "springgreen3"
col_detail1 = "tomato2"
```

# Locomotion

## Data parsing

First let's test-load one data file to see how to trim it into relevant bits. Definition in this files is so that first 4 rows and firts 6 columns are redundant.

The first portion loads and parses the raw data file lines.

```{r}
data_path <- here("Data/locomotion/")
data_files <- list.files(here("Data/locomotion/"), recursive = T)
data_files[1:8] # the first 8 files
```

Currently each file represents a set of uniquely analyzed individuals and hence no additional complications arise (like, e.g., having two files with the same individual assayed on two occasions).

In the next step we test the approach on several steps. First - we process a sample CSV file, which is unstructured and contains a lot of spurious lines and data (e.g., control variables and comments generated by the unit).

```{r}
# read in one specific file
dat_temp <- readLines(paste(data_path, data_files[1], sep = ''))
glimpse(dat_temp)
```

The loaded data is just a vector of strings, each being a line from the original CSV file. In the next chunk we skip the first 4 lines (fixed number, lines containing technical parameters of the units), and load 5 lines (which excludes the header line - so in fact 6 lines), skipping the last technical line. At the end we clean the file (removing empty columns `2:6` and wells `c(F6, F7, F8)` - they are always empty in our system). Adjust as needed. The resulting file contains each assayed well as separate column, and for each there are 5 times intervals of locomotion monitoring.

```{r}
dat_temp_df <- read.csv(text = dat_temp, header = T, sep = ',',
                        quote = '\"', dec = '.', skip = 4, nrows = length(dat_temp) - 4 - 2,
                        stringsAsFactors = F)

dat_temp_df <- dat_temp_df[, -(2:6)] # remove spurious columns
dat_temp_df <- dat_temp_df %>% select(!(F6:F8)) #remove wells that do not contain data
dat_temp_df

glimpse(dat_temp_df)
```

Here we extract and append the run (subject) ID.

```{r}
head_temp <- readLines(paste(data_path, data_files[1], sep = ''), n = 4)

# using RE - this method is more flexible as the structure and location of ID can change

# both of the below definitions will work, but second is more precise
# it uses the exact format of the run ID

id_index <- grep('Subject Identification', head_temp)
id_index <- grep('.*Subject Identification\\\",\"([A-Z0-9]{7}_B_[0-9]{6}_[0-9]{1,2})\\\"', head_temp)
run_id <- gsub('.*Subject Identification\\\",\"([A-Z0-9]{7}_B_[0-9]{6}_[0-9]{1,2})\\\"', '\\1', head_temp[id_index])
dat_temp_df$Datafile_ID <- run_id

assay_date <- str_sub(run_id, 11, 16)
dat_temp_df$date <- as.Date(assay_date, format = "%y%m%d")
glimpse(dat_temp_df)
```

Change to long format. Now each well x time combination has it's separate row, and since we have datafile ID we can link wells to specific individuals - e.g., to link-in sex information. We also rename variable according to convention: categorical variables - `Names_start_with_upper_case`; continuous variables - `all_lower_case`.

```{r}
dat_temp_df <-
  dat_temp_df %>%
  pivot_longer(names_to = 'well_id', values_to = 'arena_distance', cols = matches('[A-H][1-9]')) %>%
  rename(time = TIME, temperature = TEMPERATURE, round = ROUND,
         Variable = VARIABLE, Date = date, Well_ID = well_id)

head(dat_temp_df)
```

We have to add the `Individuals_ID` variable to be able to link locomotion data to sex data. It will serve to link Datafile_ID with respective Individuals_ID - and through it with appropriate well number. The run register contains several variables used to group individuals into several blocks that may share some of the systematic variation.

```{r}
run_meta <- read_delim(here('Data', 'run_data', 'ID_metadata.csv'), delim = ';')
run_meta %>%
  kbl() %>% kable_material(c('striped'))
```


```{r}
run_register <- read_delim(here('Data', 'run_data', 'run_register_pilot2.csv'), delim = ';')
glimpse(run_register)

dat_temp_df <- dat_temp_df %>%
  left_join(select(run_register, Datafile_ID, Individuals_ID, Exp_block, Batch_ID))

dat_temp_df <- dat_temp_df %>%
    mutate(Individuals_ID_well = paste0(Individuals_ID, '_', Well_ID))

dat_temp_df <- dat_temp_df %>% select(Individuals_ID_well, Individuals_ID, Datafile_ID, Date, Batch_ID, Exp_block,
                                      temperature, round, arena_distance)
glimpse(dat_temp_df)
```

Writing a function and using `map` to apply data loading and wrangling to all files. Note: the function uses the pattern found in text files so an important point - do not re-save Zantiks CSV files with any external software (be it MS Excel, Numbers, Google Sheets, etc.) as it will mess up with the formatting and the way text strings are coded. Adjust REs accordingly to adapt it to your file structure whenever needed.

```{r}
data_compiler <- function(filename, data_path, run_register) {
  
  ## ARG filename     vector or list of file names to process (only files, no full paths)
  ## ARG data_path    text string with the path to access all files
  ## ARG run_register database of all runs with datafile IDs and sexing IDs
  
  ## ARGS to develop: passing custom RE, custom wells to skip, custom columns to skip
  
  dat_temp <- readLines(paste(data_path, filename, sep = ''))
  
  # file parsing
  dat_temp_df <- read.csv(text = dat_temp, header = T, sep = ',',
                          quote = '\"', dec = '.', skip = 4, nrows = length(dat_temp) - 4 - 2,
                          stringsAsFactors = F)
  
  ## these line are design specific - for now the function has close form on those
  ## possible to implement as additional argument
  
  dat_temp_df <- dat_temp_df[, -(2:6)]
  dat_temp_df <- dat_temp_df %>% select(!(F6:F8))
  
  # extract headers
  head_temp <- readLines(paste(data_path, filename, sep = ''), n = 4)
  
  # using RE - this method is more flexible as the structure and location of ID can change
  id_index <- grep('.*Subject Identification\\\",\"([A-Z0-9]{7}_B_[0-9]{6}_[0-9]{1,2})\\\"', head_temp)
  run_id <- gsub('.*Subject Identification\\\",\"([A-Z0-9]{7}_B_[0-9]{6}_[0-9]{1,2})\\\"', '\\1', head_temp[id_index])
  dat_temp_df$Datafile_ID <- run_id
  
  assay_date <- str_sub(run_id, 11, 16)
  dat_temp_df$date <- assay_date
  
  dat_temp_df <-
  dat_temp_df %>%
  pivot_longer(names_to = 'well_id', values_to = 'arena_distance', cols = matches('[A-H][1-9]')) %>%
  rename(time = TIME, temperature = TEMPERATURE, round = ROUND,
         Variable = VARIABLE, Date = date, Well_ID = well_id)
  
  dat_temp_df <- dat_temp_df %>%
    left_join(select(run_register, Datafile_ID, Individuals_ID, Exp_block, Batch_ID))
  
  dat_temp_df <- dat_temp_df %>%
    mutate(Individuals_ID_well = paste0(Individuals_ID, '_', Well_ID))
  
  dat_temp_df$Filename <- filename
  
  dat_temp_df <- dat_temp_df %>% select(Individuals_ID_well, Individuals_ID, Datafile_ID, Date, Filename, Exp_block, Batch_ID,
                                      temperature, round, arena_distance)
  
  return(dat_temp_df)
}
```

Process the files using the function, mapping it row-wise into a new data-frame.

```{r message = F}
# Not run: test
# data_compiler(data_files[1], data_path, run_register)

data_locomotion <- map_dfr(data_files, ~ data_compiler(.x, data_path = data_path, run_register = run_register))

length(unique(data_locomotion$Datafile_ID)) # should be 8 distinct files

glimpse(data_locomotion)
```

## Adding sex information

Below we load the sex information (referenced to our data via the `Individuals_ID` data from the sex registry file) and left-join it with the locomotion data.

```{r}

sex <- read_csv(here("Data", "run_data", "position_ID_sex_pilot2.csv"))


sex <- sex %>%
  mutate(Individuals_ID_well = paste0(Indviduals_ID, "_", Wellplate_location)) %>%
  select(Individuals_ID_well, Sex)

# join together

data_locomotion <- data_locomotion %>%
  left_join(sex, by = "Individuals_ID_well")

data_locomotion$Round_f <- as.factor(data_locomotion$round)
```

Create final dataset.

```{r}
data_locomotion <- data_locomotion %>%
  select(Individuals_ID_well, Individuals_ID, Datafile_ID, Date, Exp_block, Batch_ID, arena_distance, Sex, Round_f)

data_locomotion$Sex <- as.factor(data_locomotion$Sex)
data_locomotion$Round_f <- as.factor(data_locomotion$Round_f)
head(data_locomotion)
```



## Example visualisations nad basic summaries and simple analysis

Histograms present raw and log-transformed total distance data. Scatter-whisker plot shows ranges of distance data (min to max distance travelled in total) with outliers marked by points.

```{r}
data_locomotion_avg <- data_locomotion %>%
  group_by(Individuals_ID_well) %>%
  summarise(avg = mean(arena_distance))

# raw data variation
data_locomotion_avg %>%
  ggplot(aes(x = avg)) +
  geom_histogram(fill = col_accent1) +
  theme_classic() + theme(text = element_text(size = 15)) +
  xlab("Mean arena distance")

# log scale
data_locomotion_avg %>%
  ggplot(aes(x = log(avg+1))) +
  geom_histogram(fill = col_accent1) +
  theme_classic() + theme(text = element_text(size = 15)) +
  xlab("Mean log(arena distance)")

data_locomotion %>%
  ggplot(aes(x = Individuals_ID_well, y = log(arena_distance+1))) +
  geom_boxplot(width = 0, outlier.size = 0.7, col = col_accent1) +
  theme_classic() + theme(axis.text.x = element_blank()) +
  ylab("Arena distance") + xlab("Individuals")
```

We can also visualise sexual differences.

```{r}

#violin plot of distance grouped by sex
library(ggpubr)

violin <- na.omit(data_locomotion) %>% 
  group_by(Individuals_ID_well) %>% 
  summarise(arena_distance = log(mean(arena_distance) +1), Sex = unique(Sex)) %>% 
  ggviolin(., x = "Sex", y = "arena_distance", add = c("jitter", "mean_se"),
           error.plot = "crossbar", fill = col_accent1, lwd = 0) +
  labs(y = "log(Mean arena distance)")
violin
```


Simple linear model to explore undelrying variation.

```{r}
# model: variance between rounds, individuals and batches, fixed effect of sex and assay date
model1 <- lmer(scale(log(arena_distance+1)) ~ Sex + as.factor(Date) + (1|Individuals_ID_well) + (1|Exp_block),
             data = data_locomotion)
model1.1 <- lmer(scale(log(arena_distance+1)) ~ Sex + as.factor(Date) + (1|Exp_block),
             data = data_locomotion)
summary(model1)
anova(model1, model1.1)
qplot(residuals(model1)) + theme_classic()

# model: additional variation in sex effect between individuals (i.e. sex-specific between individual variance)
model2 <- lmer(scale(log(arena_distance+1)) ~ Sex + as.factor(Date) + (Sex-1|Individuals_ID_well) + (1|Exp_block),
             data = data_locomotion)


# marginally off convergence but let's proceed
summary(model2)$coef %>%
  kbl() %>%
  kable_material(c("striped"))

summary(model2)$varcor %>%
  kbl() %>%
  kable_material(c("striped"))
# males tend to have larger vairance in the reposne

anova(model1, model2) %>% kbl() %>% kable_material(c("striped"))
# difference in sex-specific variances significant (likelihood-ration test)
```

Below the analogues of the above models fittewd using the `lme` function (i.e., allowing for between-sex heteroscedasticity in residuals).

```{r}
model1.lme <- lme(scale(log(arena_distance+1)) ~ Sex + as.factor(Date),
               random = list(~1|Exp_block, ~1|Individuals_ID_well),
             data = data_locomotion, na.action = na.omit)
summary(model1.lme)
model2.lme <- lme(scale(log(arena_distance+1)) ~ Sex + as.factor(Date),
               random = list(~1|Exp_block, ~Sex-1|Individuals_ID_well),
             data = data_locomotion, na.action = na.omit)
summary(model2.lme)
## testing of sex-heterogeneity in between-individual variance
anova(model1.lme, model2.lme)

model2.lme.h <- lme(scale(log(arena_distance+1)) ~ Sex + as.factor(Date),
               random = list(~1|Exp_block, ~Sex-1|Individuals_ID_well),
               weights = varIdent(form=~1|Sex),
             data = data_locomotion, na.action = na.omit)
summary(model2.lme.h)
## testing of sex-specific heteroscedasticity of residual variance
anova(model2.lme, model2.lme.h)
```



# Y-maze

## Data loading

First we load the y-maze data and tidy it up to separate summary data from zone changes data.

```{r}
## parse datafiles into a nested tibble
data_path <- here('Data/ymaze/')
data_files <- list.files(here('Data/ymaze/'), recursive = T)
data_files[1:8]
```

The below parser identifies lines in the dataset that directly relate to zone-switching data and extracts them, or (when `summary = TRUE`) it extract the arena distances summaries from the bottom section of the file.

```{r}
# helper functions extracting the data rows and the header rows
data_parser <- function(pattern, path, filename, summary = FALSE) {
  dat_temp <- readLines(paste(path, filename, sep = ''))
  zone_change_index <- grep(pattern, dat_temp)
  
  if(summary == FALSE) {
    return(read_delim(file = dat_temp[zone_change_index], col_names = F, delim = ',',
                      quote = '\"' # skip = 4, nrows = length(dat_temp) - 4 - 1)
    ))
  } else {
    return(read_delim(file = dat_temp[-zone_change_index], col_names = T, delim = ',',
                      quote = '\"', skip = 6, n_max = 3))
  }
}

# test the parser
# here we simply check that the selected pattern to be looked for (`Arena`) is indeed present in the file.
pattern1 <- "Arena" # defines what should contain each line that we look for
test1 <- readLines(paste(data_path, data_files[1], sep = ''))
id_test <- grep(pattern1, test1) # use (simplified) RE to select lines
```

```{r}
# this extracts (messy) run and temporary data from each file
test_dat <- read_delim(file = test1[-id_test], col_names = T, delim = ',',
                      quote = '\"', skip = 6, n_max = 3)

# helper function that parses the (messy) run data into a readable format)
head_parser <- function(path, filename) {
  dat_temp <- readLines(paste(path, filename, sep = ''), n = 4)
  return(read_delim(file = dat_temp,
                    delim = ',',
                    col_names = F))
}
```

## Data organisation and cleaning

The below code generates a nested tibble (grouped by single analysis output files, i.e., `Filename`).

```{r}
# create tibble with raw data (nested: data and header nested under file names)
dat_raw <- tibble(data_files = data_files) %>%
  mutate(data = map(data_files, 
                    ~ data_parser(pattern1,
                                  data_path,
                                  .x, summary = FALSE))) %>%
  mutate(head = map(data_files, ~ head_parser(data_path, .x)))

# this removes the redundant 'Arena' column
dat_raw[[2]] <- dat_raw[[2]] %>%
  map(~ select(.x, !c(X3)))

# rename variables in sub-tibble based on their real content
dat_raw[[2]] <- dat_raw[[2]] %>%
  map(~ rename(.x, time = X1, Info = X2, Arena = X4, Action = X5, Zone_no = X6))

# reformat the head sub-tibble
dat_raw[[3]] <- dat_raw[[3]] %>%
  map(~ pivot_wider(.x, names_from = X3, values_from = X4)) %>%
  map(~ rename(.x, Datafile_ID = `Subject Identification`)) %>%
  map(~ select(.x, Apparatus, Datafile_ID))

# check the modifications
dat_raw[[2]][[1]]
dat_raw[[3]][[1]]
```

The below code processes arena movement summaries contained in the bottom sections of output files; this data is not further used in the current protocol.

```{r}
# parse summary data from a file into a separate tibble - this is not used for now
# processed only for consistency
dat_raw_summ <- tibble(data_files = data_files) %>%
  mutate(data = map(data_files, ~ data_parser(pattern1,
                                data_path,
                                .x,
                                summary = T)))
dat_raw_summ[[2]] <- dat_raw_summ[[2]] %>%
  map(~ select(.x, !c(X1, X2, X3))) %>%
  map(~ rename(.x, Summary_stat = X4))
dat_raw_summ[[2]][[1]]
```

Unnest the tibble and select relevant variables.

```{r}

dat_un <- dat_raw %>%
  unnest(head) %>%
  unnest(data)

dat_un <- dat_un %>%
  select(data_files, Datafile_ID, time, Arena, Action, Zone_no) %>%
  rename(Data_file = data_files)

```

Turn into wider format with enter/exit columns, add row ID to maintain order if needed.

```{r}
dat_un <- dat_un %>%
  mutate(Row_ID = row_number()) %>%
  pivot_wider(names_from = Action, values_from = Zone_no) %>%
  rename(Exit_zone = Exit_Zone, Enter_zone = Enter_Zone)
dat_un
```

Bin into 10-min intervals (if binning would be needed or only first 10 mins of exploration used). Then sort the dataset into individual arenas and chronologically within arenas, and then in enter-exit order at the lowest level.

```{r}
dat_an <- dat_un
dat_an <- dat_an %>%
  mutate(Bin = ifelse(time > 600 & time < 1200, 1,
                      ifelse(time > 1200 & time < 1800, 2,
                             ifelse(time > 1800 & time < 2500, 3, NA))))

dat_an <- dat_an %>%
  arrange(Data_file, Datafile_ID, Arena, time, Exit_zone)
dat_an
```

Error checking - do all enter zones have a matching exit zone (if enter and exit exist)?

```{r}
dat_an <- dat_an %>%
  mutate(Zone = ifelse(Enter_zone == lead(Exit_zone), Enter_zone, 666)) %>%
  mutate(t_enter = ifelse(Enter_zone >= 1, time, 666)) %>%
  mutate(t_exit = ifelse(Exit_zone >= 1, time, 666))

dat_an %>% filter(Zone == 666)
dat_an %>% filter(t_enter == 666)
dat_an %>% filter(t_exit == 666)

# ALL GOOD! Note - this step is v. important and serves to test
# if data points were sorted correctly
# Single detected mistakes are likely final entries that failed to exit before assay end


# Let's filter out the non-conforming cases and re-confirm the rest is ordered correctly
# This stage is critical: dplyr filter() function is terribly unintuitive - with the logical
# condition "NOT" (!) it also drops NA values - thus we have to ensure with replace_na() they are kept
# to preserve the ordering of enter-exit events

dat_an <- dat_an %>% filter((Zone != 666) %>% replace_na(TRUE))
dat_an <- dat_an %>%
  arrange(Data_file, Datafile_ID, Arena, time, Exit_zone)
dat_an <- dat_an %>%
  mutate(Zone = ifelse(Enter_zone == lead(Exit_zone), Enter_zone, 666)) %>%
  mutate(t_enter = ifelse(Enter_zone >= 1, time, 666)) %>%
  mutate(t_exit = ifelse(Exit_zone >= 1, time, 666))
dat_an %>% filter(Zone == 666)
```

Simplify data by putting enter and exit data in one row.

```{r}
dat_an <- dat_an %>%
  # filter(is.na(Zone)) %>% # this filter is just for testing purposes (it removes the 'Exit_zone' portion of data)
  select(Data_file, Datafile_ID, time, Arena, Row_ID, Bin, Zone, t_enter, t_exit)
dat_an <- dat_an %>%
  mutate(t_exit = lead(t_exit))
dat_an <- na.omit(dat_an)
dat_an <- dat_an %>%
  mutate(t_zone = t_exit - t_enter)
dat_an
```

Remove center zone (middle of the Y-maze). In an alternative version of analysis this can be included by considering the middle zone as equally valid spatial choice for flies. Below we simplify the analysis by considering only arm zones.

```{r}
dat_an2 <- dat_an %>% filter(Zone != 4)
dat_an2
```

## Y-maze movements analysis

We need to work separately for each individual - the easiest is to separate individuals into their own sub-tibbles and work on them by vectorising operations - to achieve this we have to identify each individual (by pasting together file name and arena).

```{r}
well_arena <- read_delim(here('Data', 'run_data', 'well_arena_corresp.csv'), delim = ';')

dat_an2 <- dat_an2 %>%
  left_join(select(run_register, Datafile_ID, Individuals_ID, Plate, Unit_ID), by = "Datafile_ID") %>%
  mutate(Ymaze_arena = paste0(Plate, "_", Arena)) %>%
  # mutate(fly_id = paste(gsub('[A-Za-z0-9]+\\/([A-Za-z0-9_-]+)\\.csv', '\\1', data_files), arena, sep = "_"))
  # mutate(fly_id = paste0(Datafile_ID, "_", Ymaze_arena)) %>% # not really necessary
  left_join(select(well_arena, Ymaze_arena, Plate48well), by = "Ymaze_arena") %>%
  mutate(Individuals_ID_well = paste0(Individuals_ID, "_", Plate48well)) %>%
  select(Datafile_ID, Individuals_ID, Individuals_ID_well, Ymaze_arena, time, Bin, Zone, t_zone)

# split datafile into individual flies
dat_an2 <- dat_an2 %>% split(., .[, "Individuals_ID_well"])

dat_an2 <- dat_an2 %>%
  map(~ mutate(.x, Lag_zone = lag(Zone))) %>%
  map(~ mutate(.x, Turn = case_when(Lag_zone==1 & Zone==2 ~ 'L',
                                  Lag_zone==1 & Zone==3 ~ 'R',
                                  Lag_zone==2 & Zone==1 ~ 'R',
                                  Lag_zone==2 & Zone==3 ~ 'L',
                                  Lag_zone==3 & Zone==1 ~ 'L',
                                  Lag_zone==3 & Zone==2 ~ 'R',
                                  # lag_zone==zone ~ 'X', # this enables additional decision type = stay in the given zone
                                  TRUE ~ NA_character_ ))) %>%
  map(~ select(.x, Datafile_ID, Individuals_ID, Individuals_ID_well, Ymaze_arena, time, Bin, Zone, t_zone, Turn))

dat_an3 <- bind_rows(dat_an2)
dat_an3 <- dat_an3 %>%
  arrange(Datafile_ID, Individuals_ID_well, Bin)

dat_an4 <- na.omit(dat_an3)
dat_an4
```

Resulting data could be further refined, e.g. by removing entries with `t_zone` below certain threshold (i.e., ignoring cases where a flies only very briefly entered a zone and exitted right away).

## Analysis of trigrams

There are several paradigms of anaylsing Y-maze data. One is based on tetragram analysis (i.e., sequences of 4 consecutive turns in the maze). Here we simplify it to trigram analsyis to increase the power and effective number of consecutive movement sequences.
```{r}
dat_tri <- dat_an4 %>%
  group_by(Individuals_ID_well)

dat_tri <- dat_tri %>%
  mutate(Trigram = str_c(Turn, lead(Turn), lead(Turn,2))) %>%
  ungroup() %>%
  select(Individuals_ID_well, Turn, Trigram)
dat_tri
```

We can now summarise trigrams and turns:

```{r}
all_trigrams <- unique(dat_tri$Trigram)

tri_long <- dat_tri %>%
  select(-Turn) %>%
  na.omit() %>%
  group_by(Individuals_ID_well) %>%
  table() %>%
  as_tibble() %>%
  arrange(Individuals_ID_well)

tri_wide <- tri_long %>% pivot_wider(names_from = Trigram, values_from = n)

turn_long = dat_tri %>%
  select(-Trigram) %>%
  na.omit() %>%
  group_by(Individuals_ID_well) %>%
  table() %>%
  as_tibble() %>%
  arrange(Individuals_ID_well)

turn_wide <- turn_long %>% pivot_wider(names_from = Turn, values_from = n)

data_ymaze <- tri_wide %>%
  left_join(turn_wide, by = 'Individuals_ID_well') %>%
  mutate(total_turns = L+R,
         reps = LLL + RRR,
         alter = RLR + LRL,
         partial = RRL + RLL + LRR + LLR,
         rel_reps = (reps*100)/total_turns,
         rel_alter = (alter*100)/total_turns,
         rel_R = (R*100)/total_turns,
         rel_L = (L*100)/total_turns,
         asymmetry = 1 - (R/L)) # 0 = symmetrical, <1 = 

data_ymaze
```

## Linking to sex data

```{r}
data_ymaze <- data_ymaze %>%
  left_join(sex, by = 'Individuals_ID_well')
```

## Example visualisations of y-maze data and simple analysis

Distribution of trigrams

```{r}
tri_long %>%
  # filter(n > 0) %>%
  ggplot(aes(x = Trigram, y = n)) +
  geom_bar(stat = "sum", fill = "slateblue2") +
  theme_classic() + labs(x = 'Trigram', y = 'Total number') +
  theme(legend.position = "none", text = element_text(size = 15))
```

Correlation of locomotor activity with alteration and repetition patterns. Patterns suggest a zero-inflated model may be warranted (not explored in this paper).

```{r}
data_ymaze %>% left_join(data_locomotion_avg, by = 'Individuals_ID_well') %>%
  select(avg, Sex, rel_reps, rel_alter) %>%
  ggplot(aes(x = avg, y = rel_reps, colour = Sex)) +
  geom_point() + geom_smooth(method = 'lm') +
  scale_color_manual(values = c(col_accent1, col_accent2)) +
  theme_classic() + labs(x = 'Locomotion activity', y = 'Proportion of repetitions')

data_ymaze %>% left_join(data_locomotion_avg, by = 'Individuals_ID_well') %>%
  select(avg, Sex, rel_reps, rel_alter) %>%
  ggplot(aes(x = avg, y = rel_alter, colour = Sex)) +
  geom_point() + geom_smooth(method = 'lm') +
  scale_color_manual(values = c(col_accent1, col_accent2)) +
  theme_classic() + labs(x = 'Locomotion activity', y = 'Proportion of alterations')
```

General variation in repetition and alteration behaviour.

```{r}
data_ymaze %>% pivot_longer(cols = c('rel_reps', 'rel_alter'), names_to = 'Type') %>%
  ggplot(aes(x = value, fill = Type)) +
  geom_histogram() +
  theme_classic() +
  scale_fill_manual(values = c(col_accent1, col_accent2), labels = c("Alterations", "Repetitions")) +
  labs(x = "Proportion of repetitions", fill = "Behaviour")
```

Sex differences in Y-maze behaviour

```{r}
violin <- data_ymaze %>% 
  ggviolin(., x = "Sex", y = "rel_reps", add = c("jitter", "mean_se"),
           error.plot = "crossbar", fill = col_accent2, lwd = 0) +
  labs(y = "Proportion of repetitions")
violin

violin <- data_ymaze %>% 
  ggviolin(., x = "Sex", y = "rel_alter", add = c("jitter", "mean_se"),
           error.plot = "crossbar", fill = col_accent1, lwd = 0) +
  labs(y = "Proportion of alterations")
violin

violin <- data_ymaze %>% 
  ggviolin(., x = "Sex", y = "asymmetry", add = c("jitter", "mean_se"),
           error.plot = "crossbar", fill = col_detail1, lwd = 0) +
  labs(y = "Handedness (turning asymmetry)")
violin
```

Formal analysis if alteration behaviour depends on overall locomotion activity of flies and if it interacts with sex.

```{r}
# model: variance between rounds, individuals and batches, fixed effect of sex and assay date
model3 <- glm(alter ~ Sex * avg,
             data = data_ymaze %>% left_join(data_locomotion_avg, by = 'Individuals_ID_well'),
             family = 'poisson')
summary(model3)
data_ymaze %>% left_join(data_locomotion_avg, by = 'Individuals_ID_well') %>%
  ggplot(aes(x = avg, y = alter, colour = Sex)) +
  geom_point() + geom_smooth(method = 'lm') +
  scale_color_manual(values = c(col_accent1, col_accent2)) +
  theme_classic() + labs(x = 'Locomotion activity', y = 'Number of alterations')
# there is one clear outlier that can be an artifact


model4 <- glm(alter ~ Sex * avg,
             data = data_ymaze %>% left_join(data_locomotion_avg, by = 'Individuals_ID_well') %>% filter(alter < 100),
             family = 'poisson')
summary(model4)
data_ymaze %>% left_join(data_locomotion_avg, by = 'Individuals_ID_well') %>%
  filter(alter < 100) %>%
  ggplot(aes(x = avg, y = alter, colour = Sex)) +
  geom_point() + geom_smooth(method = 'lm') +
  scale_color_manual(values = c(col_accent1, col_accent2)) +
  theme_classic() + labs(x = 'Locomotion activity', y = 'Number of alterations')
```




# Habituation experiment

Analysis of habituation data based on Allen TA, Budenberg WJ (2021). Replicating Light-Off Startle Responses in Drosophila melanogaster. BiorXiv.


## Load data

```{r}
#specify directory of zantiks habituation files
data_path <- here("data", "habituation/") 

#create list of files from directory
file_list <- list.files(data_path)

#create header from first file
df <-
  paste0(data_path, file_list[1]) %>%
  read_csv(skip=4,col_names = TRUE, guess_max = 100) %>%
  head(0)

#create new list without demographic info
new_list<- c()

for (i in file_list){
  new_list[[i]] <-
    read_csv(paste0(data_path, i),
             skip=4, col_names = TRUE, guess_max = 100) %>%
    head(-1)
}

#append all files to df
for (i in new_list){
  df<-add_row(df,i)
}
```


## Format, select and rename variables

In the course of it we also remove wells F6, F7, F8 (they are always empty).

```{r}
df <- df %>% select(!c(RUNTIME, UNIT, TIMESLOT, TEMPERATURE))
#convert variables to factors for anova
df<-as_factor(df,BLOCK)
df<-as_factor(df,TYPE)

df <- df %>% rename(Datafile_ID = PLATE_ID, time_bin = TIME_BIN,
                    Block = BLOCK, Trial = TRIAL, Type = TYPE,
                    pre_post_counter = PRE_POST_COUNTER,
                    startle_number = STARTLE_NUMBER)

df <- df %>% select(-c(F6:F8), -c(F6MSD:F8MSD))
```


## Create file with total population columns

Here we use the mean squared distance data and total distance travelled from each well to assemble a plate-level (hence - population) measure of fly behaviour during the trial. These produce two summary statistics of fly activity in arenas.

```{r}
pop_data<-mutate(df,total_dist = rowSums(select(df,!ends_with("MSD"),
                                                -Datafile_ID, -time_bin, -Block,
                                                -Trial, -Type, -pre_post_counter,
                                                -startle_number)))
pop_data<-mutate(pop_data,total_act = rowSums(select(df,ends_with("MSD"))))
```



## Create file with well factor and distance variable

```{r}
dfile_dist <- df %>% 
  select(!ends_with("MSD")) %>%
  gather(key = "Well", value = "distance", -Datafile_ID,
         -time_bin, -Block, -Trial, -Type, -pre_post_counter,
         -startle_number) %>%
  convert_as_factor(Well)

# create file with well factor and MSD activity dv only
dfile_act<- df %>%
  select(ends_with("MSD")) %>%
  gather(key = "Well", value = "activity") %>%
  convert_as_factor(Well)

# remove duplicate well variable before adding activity data
dfile_act <- select(dfile_act, -'Well')

# add activity column to rest of data
df <- add_column(dfile_dist, dfile_act)

# remove acclimation data
no_acclimation <- df %>%
  filter(Type != "ACCLIMATION")

# create data file with only startles from first repeat (Block == 1)
startles_only <- filter(no_acclimation, Type == "STARTLE", Block == 1)
pop_startles_only<-filter(pop_data, Type == "STARTLE", Block == 1)
```


## Merge with individual data to idenitfy flies

We also add information abou sex.

```{r}
startles_only <- startles_only %>%
    left_join(select(run_register, Datafile_ID, Individuals_ID, Exp_block, Batch_ID))

startles_only <- startles_only %>%
  mutate(Individuals_ID_well = paste0(Individuals_ID, "_", Well))

startles_only <- startles_only %>%
  left_join(sex, by = "Individuals_ID_well")
```


## Population data averaged across blocks

```{r}
pop_startles_block <-
  pop_startles_only %>%
  group_by(startle_number) %>%
  get_summary_stats(total_dist, type = "mean_sd")
```

## Additional cleaning

Below we generate overall summary of distances travelled by individual flies during startles 1 through 3, in two variants: including and excluding flies that did not move at all during all three repeats of startling.

```{r}
startles_only <- startles_only %>%
  group_by(Individuals_ID_well)

startles_only_act <- startles_only %>%
  filter(sum(distance) != 0) %>%
  ungroup()

overall_summary_act <- startles_only_act %>%
  group_by(startle_number) %>%
  get_summary_stats(distance, type = "mean_sd")

overall_summary <- startles_only %>%
  group_by(startle_number) %>%
  get_summary_stats(distance, type = "mean_sd")
```


# Simple graphs

```{r}
# pop habituation averaged across blocks graph
gg_pop_hab_block <- ggplot(data=pop_startles_block, aes(x = startle_number, y = mean,)) +
  xlab("Trial") +
  ylab("Average Population Distance Travelled (pixels)") +
  geom_errorbar(aes(ymin=mean-(sd/sqrt(2)), ymax=mean+(sd/sqrt(2))), width=1, color = col_accent1) +
  geom_line() +
  geom_point() + theme_classic() + theme(text = element_text(size = 15))
gg_pop_hab_block


# habituation data by individual - only active flies
gg_habituation<-ggplot(data=startles_only_act, aes(x = startle_number, y = distance)) +
  facet_wrap(facets = ~ Individuals_ID_well) +
  geom_line() +
  geom_point(col = col_accent1) + theme_classic()
gg_habituation
```


# Formal random slope analysis

```{r}

model5 <- lmer(distance ~ Sex*startle_number + (1|Individuals_ID_well) + (1|Exp_block),
               data = startles_only_act)
summary(model5)


model6 <- lmer(distance ~ Sex*startle_number + (1+startle_number|Individuals_ID_well)  + (1|Exp_block),
               data = startles_only_act)
summary(model6)

## comparison of intercept-only and random slopes models
anova(model5, model6)
```
